\documentclass[11pt]{article}

\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{swmacros}
\usepackage{graphicx}
\usepackage{float}
\usepackage{color}


%\usepackage[top=1in, bottom=1in, left=.5in, right=.5in]{geometry}
%\usepackage[font=small,labelfont=bf]{caption}

\setlength\parindent{0pt}
% Title.
% ------
\title{STAT 240 Final Project}
\author{Rebecca Barter, Andrew Do and Kellie Ottoboni}



\begin{document}

\maketitle

 \section{Introduction}
Over the last two decades developing countries have seen an increase in the number of new primary school entrants, driven in part, by the elimination of school fees. For example, between 1999 and 2004 the number of new entrants to primary school in sub-Saharan Africa increased by more than 30 percent (\cite{unesco2007}). Although this influx of new students is undeniably a positive development, steps needs to be taken to ensure that the quality of education is not diminished. For example, by 2005, the average first grade class size in Kenya had swelled to 83, with 28 percent of first grade classes containing more than 100 students (\cite{duflo2007}). Moreover, many of the new students were significantly less prepared than those in the past.\\

Unfortunately, little prior work had been undertaken to evaluate the most effective methods of handling such an influx of students. In a randomized experiment, Duflo et al. aim to answer several questions related to a number methods of resource allocation in primary education. In particualr, the investigators aim to assess the impact of reduction in pupil-teacher ratios, implementing tracking (separating classes into high and low streams based on prior test scores) and different institutional environments (type of teacher, and whether or not the school undertakes teacher monitoring and education).\\

In this report, we investigate the data obtained from the study undertaken by Duflo et al, with a focus on evaluating the impact of tracking on student achievement. 
 
\section{Tracking}
Tracking involves separating pupils by academic ability within schools. In particular, a student is assigned to the high stream if their prior achievement is above the median, and is assigned to the low stream otherwise. There have been multitudes of studies involving the effects tracking in developed countries, with no overall consensus on whether it is beneficial or detrimental to future student achievement. However those who claim that tracking is beneficial to students have several arguments. For example the reduced skill differential has the potential to allow for better lesson execution and time allocation by teachers; they can focus on teaching at a level that will benefit all students in the class, rather than having to cater to a wide range of abilities. Further, it is possible that ensuring that students are placed in classes of the appropriate difficulty levels will reduce behavioral outlashing by students. Finally, proponents argue that the ``value-added'' is maximized within each group.\\

In contrast, critics of tracking argue that in the absence of tracking, high performing students are given the opportunity to synthesize ideas they've learned by teaching low performers. Further, critics pose the idea that tracking is a self-fulfilling prophecy; students in the low stream will achieve lower than they otherwise might, simply because they have been put in a class that implies that they are not as able. This idea is reinforced by the argument that teachers may require less of students in the low stream, and thus that the education gap will widen between the high and low achieving groups.\\

Through our analysis of the data provided by Duflo et al., we will provide data-driven evidence for several of these arguments, and present our position on the effects of tracking on disadvantaged schools in Kenya. In particular, we aim to answer whether 1) there is value-added by introducing tracking, 2) whether tracking has a differential effect on different students of different baseline abilities, and 3) whether tracking creates a gap between students of approximately average ability, since these students can be considered to be randomly assigned to the low and high streams.
 
 \section{Study Design}
 
 The study conducted by Duflo et al. involves data from a randomized experiment spanning 18 months involving the first grade class from 210 primary schools in Western Kenya. These schools have a combined 21,000 students and prior to the experiment each school has only a single first grade class taught by a centrally-hired teacher with civil service protection (hereafter referred to as a ``civil service teacher''). The study involves several layers of randomization which are summarized in Figure~\ref{fig:randomization}. The ``Extra Teacher Program'' (ETP) provided funds to 140 schools randomly selected from the pool of 210 schools to hire an extra teacher for first grade classes. These teachers were hired locally, and earned approximately a quarter of the civil service teachers, but had the same academic qualifications. In 70 of these 140 ETP schools tracking was introduced (these schools are ``tracked'' schools), whereby the two classes were divided by initial achievement, and the classes were randomly assigned to either a civil service teacher or a contract teacher. In the other half of the ETP schools (``non tracked'' schools), students were randomly assigned to either the local contract teacher or the existing civil service teacher. Finally, half of the 70 non-tracked ETP schools and half of the tracked ETP schools were given funds to empower the local school committee to monitor and train teachers (these schools are referred to as the ``monitored'' schools).
 
 \begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]{Randomization_flow.png}
 \caption{A flowchart describing the randomization steps of the study}
 \label{fig:randomization}
 \end{figure}
 
Stream assignment in tracked schools was based on initial test scores (baseline test) which were administered locally within schools. Thus these baseline test scores are internally consistent within schools but not comparable across schools. The success of the program was assessed based on scores from a standardized mathematics and language test taken by 60 students from each school (approximately 7000 students all together) after 18 months (the end line test). Another test was also taken by the same students after 24 months (the long-term followup test). We note that the ETP funding ceased after the 18 month endline, so the tracking was no longer in place at the 24 month followup. These tests contained numeracy and literacy questions ranging from counting and identifying letters to subtracting two-digit numbers and writing words.
 
 \section{Exploratory Data Analysis}
 The original dataset contains observations for 7022 students over 106 variables, including individual question scores for each of the endline and follow-up tests, as well as information such as school ID, school district, whether or not the student came from a tracked or non-tracked school, gender, age, teacher-type and stream assignment (for students in the tracked schools). We note that the data contains data for first-grade students whose ages range hugely from 5 to 19, with the median age being 9 (Figure~\ref{fig:age}).
 
  \begin{figure}[h]
 \centering
 \includegraphics[scale=0.6]{age.pdf}
 \caption{Age ranges of first-grade students}
 \label{fig:age}
 \end{figure} 
 
 We compared the characteristics of students in tracking and in non-tracking schools (Table~\ref{tab:char}), and we found that in terms of age, gender and endline attrition (the percentage of students that were not present for the endline test), the students in tracked and non-tracked schools are extremely comparable. We did, however, find that the tracking and non-tracking schools are not distributed equally in terms of location. The 210 schools come from a total of 9 school zones, but we see that for Butere East and Municipality, there are approximately twice as many tracked schools as non-tracked schools, whereas for Khwisero West, there are more than twice as many non-tracked schools as there are tracked schools (Figure~\ref{fig:zone}). If these regions have different education standards, then this imbalance has the potential to yield biased results if we do not block our analysis by zone. \textcolor{red}{Based on this finding, we should probably do a stratified/blocked analysis on zone}
 
 
 \begin{table}[H]
 \centering
 \begin{tabular}{cccccccccc}
 \hline
 & Tracked School (n = 3613) & Non-tracked School (n = 3409)\\
 \hline
Female (\%) & 0.49 & 0.49\\
Age (mean) & 9.36 (1.47) & 9.18 (1.46)\\
Endline attrition (\%) & 0.17 & 0.17\\ \hline
 \end{tabular}
 \caption{A comparison of the characteristics of the students in tracked and non-tracked schools. The numbers in parentheses are standard deviations.}
 \label{tab:char}
 \end{table} 
 
 \begin{figure}[H]
 \centering
 \includegraphics[scale = 0.5]{school_zones.pdf}
 \caption{The number of tracked and non-tracked schools in each school zone}
 \label{fig:zone}
 \end{figure}
 
 
 \noindent Next, for students in tracked schools, we compared the characteristics for students in the high and low stream (Table~\ref{tab:charstream}). We found that the students in the high stream were slightly older than those in the low stream and were more likely to be present at the endline test.
  \begin{table}[H]
 \centering
 \begin{tabular}{cccccccccc}
 \hline
 & Low stream (n = 1808) & High stream (n = 1805)\\
 \hline
Female (\%) & 0.49 & 0.50\\
Age (mean) & 9.14 (1.47) & 9.58 (1.44)\\
Endline attrition (\%) & 0.19 & 0.16\\ \hline
 \end{tabular}
 \caption{A comparison of the characteristics of the students in high and low streams. The numbers in parentheses are standard deviations.}
 \label{tab:charstream}
 \end{table} 
 
 
 \noindent In addition, we found concerning inconsistencies in the available data. For example the initial grade percentiles provided do not correspond to the percentiles when calculated manually (Figure~\ref{fig:percentile}). The codebook that accompanied the data stated that the provided percentiles had been imputed, although what data was used to conduct the imputation and the method of imputation is not described. We thus decided to use our own calculated percentiles for our subsequent analysis.\\
 
Another issue we detected is that within tracking schools, some crossover between low and high streams occurred (Figure~\ref{fig:crossover}), although we note that this crossover is minor (only about 5.3\%), it does pose minor issues in our subsequent analyses. Duflo et al., state that the crossover \textcolor{red}{is primarily due to ***?}

 
 
  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.6]{Score_vs_Percentile.png}
 \caption{A comparison of the percentiles reported in the data and the percentiles obtained when calculating manually.}
 \label{fig:percentile}
 \end{figure} 
 
  
  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.3]{tmt_assignment.png}
 \caption{The probability of assignment to high stream versus the baseline score. If no crossover occurred, the probability would be 0 until baseline score reached 0.5, after which the probability would be 1.}
 \label{fig:crossover}
 \end{figure} 
 
 
 \section{Analysis}
 \subsection{Value-added over time by tracking}
Unfortunately since the baseline test scores were not comparable across different schools, we were unable to measure the value-added from tracking by comparing baseline with the 18 month endline scores. As a result, we thus chose to measure the long-term value-added by comparing 18 month endline scores with the 24 month follow-up scores. This comparison allows us to see if tracking yielded a lasting effect on students, even after the tracking was no longer in place.



 \subsection{Stratified permutation tests for comparing tracking with non tracking schools}

In comparison to the previous analysis, which involved comparing scores over time for the students in tracking schools, we now turn to a comparison of scores achieved by students in tracking schools with students in non-tracking schools. \\
 
We began by testing whether tracking had an effect on the 18 month follow-up scores for students of different baseline abilities.  We carried out stratified permutation tests with a t-statistic to address this question. We split students into four strata based on their percentile on their school's baseline exam score.  For this, we used the percentiles that we calculated rather than the ones supplied, due to the inconsistencies we discussed previously.  Within each stratum, we calculated the test statistic and permuted treatment assignments.  This procedure allowed us to carry out tests both within individual strata and overall for all students.  Figure~\ref{fig:tracking-stratif} shows that in each stratum, tracking has a positive effect on follow-up test scores.  The effect was significant overall and for each quartile except for the third (Table~\ref{tab:tracking-stratif}, two-sided alternative). \\

Next, we investigated the effect of tracking on the individual components of the 18 month follow-up score.  Table~\ref{tab:stratif-topics} shows the effect of tracking on each topic, by baseline quartile and overall.  Tracking increased students' average letter score, spelling score, literacy score, and math score.  As with the total score, the positive effects of tracking seemed to be less pronounced in the third quartile of students. \\

  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]{tracking-stratif.pdf}
 \caption{}
 \label{fig:tracking-stratif}
 \end{figure} 
  % latex table generated in R 3.0.2 by xtable 1.7-4 package
% Sun Apr 26 15:37:57 2015
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & Bottom quarter & Second quarter & Third quarter & Top quarter & Overall \\ 
  \hline
Difference in means & 0.963 & 1.318 & 0.798 & 1.425 & 1.124 \\ 
  t & 2.466 & 2.998 & 1.690 & 2.810 & 2.493 \\ 
  P-value & 0.013 & 0.003 & 0.091 & 0.005 & 0.000 \\ 
   \hline
\end{tabular}
\caption{Test for differences in final score, stratified by baseline quartile and overall.} \label{tab:tracking-stratif}
\end{table} % Q1a in Kellie's analysis file

% latex table generated in R 3.0.2 by xtable 1.7-4 package
% Sun Apr 26 15:38:36 2015
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & Bottom quarter & Second quarter & Third quarter & Top quarter & Overall \\ 
  \hline
Word Score & 0.048 & 0.542 & 1.017 & 1.084 & 0.661 \\ 
   & (0.963) & (0.597) & (0.319) & (0.272) & (0.188) \\ 
  Sentence Score & -0.297 & -0.761 & 0.572 & 1.173 & 0.161 \\ 
   & (0.770) & (0.450) & (0.560) & (0.235) & (0.746) \\ 
  Letter Score & 2.988 & 3.389 & 1.924 & 4.466 & 3.191 \\ 
   & (0.002) & (0.001) & (0.050) & (0.000) & (0.000) \\ 
  Spelling Score & 1.290 & 1.111 & 0.740 & 1.689 & 1.210 \\ 
   & (0.197) & (0.268) & (0.450) & (0.093) & (0.015) \\ 
  Literacy Score & 1.504 & 1.530 & 1.291 & 2.405 & 1.680 \\ 
   & (0.135) & (0.131) & (0.202) & (0.015) & (0.001) \\ 
  Math Score & 2.869 & 3.878 & 1.718 & 2.508 & 2.750 \\ 
   & (0.005) & (0.000) & (0.086) & (0.011) & (0.000) \\ 
   \hline
\end{tabular}
\caption{t-statistics and p-values for the test of differences in subject-level final score between tracking and non-tracking schools, stratified by baseline quartile and overall.} \label{tab:stratif-topics}
\end{table} % Q1b in Kellie's analysis file

We investigated the potential bias in the estimated treatment effect due to differences in school zone.  Figure~\ref{fig:stratif-zone} shows the difference in mean 18 month follow-up scores between tracking and non-tracking schools, broken down by school zone.  The effect of tracking is heterogeneous across school zones.


 \begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]{tracking_by_zone.pdf}
 \caption{}
 \label{fig:stratif-zone}
 \end{figure}
 

\newpage
 
 \begin{figure}[H]
 \centering
 \includegraphics[scale=0.5]{tracking-etp-stratif.pdf}
 \caption{}
 \label{fig:tracking-etp}
 \end{figure}
 

% latex table generated in R 3.0.2 by xtable 1.7-4 package
% Sun Apr 26 18:50:55 2015
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrr}
  \hline
 & Bottom quarter & Second quarter & Third quarter & Top quarter & Overall \\ 
  \hline
  ETP & 2.506 & 3.695 & 0.759 & 1.918 & 2.254 \\ 
   & (0.011) & (0.000) & (0.459) & (0.061) & (0.000) \\ 
  Non-ETP & 0.817 & 0.522 & 1.906 & 2.404 & 1.423 \\ 
   & (0.421) & (0.611) & (0.061) & (0.017) & (0.004) \\ 
   \hline
\end{tabular}
\caption{t-statistics and p-values for the test of difference in mean follow-up exam score between students in tracking vs non-tracking schools, stratified by ETP vs civil servant teachers.} 
\end{table} % Q5 in Kellie's analysis file


 \subsection{Regression discontinuity for comparing students in the high stream with those in the low stream}
We now aim to analyze the effect of stream assignment on students in tracked schools who initially achieved near the cutoff point. This analysis is based on the idea that students who achieved near the cutoff point have approximately equivalent abilities and it was random noise that lead to their assignment into either the high or low stream. For example, if a student slept poorly the night before the baseline test, they may have scored a few points below the cutoff point, whereas they may otherwise have scored a few points above the cutoff point. As a result, we can consider the students whose initial scores fall within a small window of the cutoff point as being randomly assigned into either the high or low stream, and we can thus evaluate the treatment effect of assignment to the high stream (for example) as if it were a random assignment for the students within the cutoff window.\\
If we plot the baseline score versus endline score (Figure~\ref{fig:RD_big}), visually, there does not appear to be a jump at the cutoff point (which is what we would expect to see in the presence of a regression discontinuity)

However, when zooming in on a small window around the cutoff point (Figure~\ref{fig:RD_scatter}), we see that there appears to be a minor discontinuity, with those students almost exactly at the cutoff point who are put into the high stream appear to perform worse than the students who are put into the low stream.

  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.6]{RD_initial.png}
 \caption{Aggregated scatterplot of baseline score versus 18 month endline score. Each point is the average score of all students who fall within the corresponding score bin, each of width 0.3. The high stream point to the left of the cutoff point is a reflection of the crossover.}
 \label{fig:RD_big}
 \end{figure}

  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.6]{RD_scatter.pdf}
 \caption{A scatterplot of baseline percentile versus 18-month score within a window of width 10 percentile points (5 percentile points in each direction around the cutoff point) with loess fitted curves for the high and low stream (calculated using the students who were placed into the high stream only)}
 \label{fig:RD_scatter}
 \end{figure}

Figure~\ref{fig:pval_window} presents the (intention to treat) $p$-values of a permutation test testing the difference in means within each school zone, as well as the combined $p$-value from the stratified-by-zone permutation test (the rightmost cluster of bars). We see that for most school zones there is no difference between the students in the cutoff window assigned to the low stream and the upper stream, however, within a very small window of the cutoff point. The only zone for which we obtain a statistically significant result is for the South Wanga school zone for the students in the 20-percentile width window of the cutoff point (the window consists of students who scored from the 40th to the 60th percentile in the baseline scores). However, this window may be too large to still consider the students as randomly assigned to the high and low streams, and we may simply be detecting the fact that overall, the students in the high streams perform better than those in the low streams. 
 
  \begin{figure}[H]
 \centering
 \includegraphics[scale=0.6]{RD_pval.pdf}
 \caption{Bar plot of permutation test $p$-values for differences in means between the low stream and high stream for windows of varying widths (5, 10, 15 and 20 percentile points) about the cutoff point of the 50th percentile. The 5-percentile width window contains a total of 137 students, the 10-percentile width window contains a total of 225 students, the 15-percentile width window contains a total of 405 students and the 20-percentile width window contains a total of 509 students.}
 \label{fig:pval_window}
 \end{figure}
 
 
 
 
 
 
 \section{Conclusion}
 
 
 \bibliographystyle{apalike}
\bibliography{references}
 
\end{document}
